{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Unsupervised learning Credit Card.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blindness120/blindness120.github.io/blob/master/Unsupervised_learning_Credit_Card.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "166ba598"
      },
      "source": [
        ""
      ],
      "id": "166ba598",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADCZgr3VR9BO"
      },
      "source": [
        "# !pip install imblearn & SMOTE package"
      ],
      "id": "ADCZgr3VR9BO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efSREvs2R9hJ"
      },
      "source": [
        "# !pip install imblearn ## installing imblearn in the event this is forgotten"
      ],
      "id": "efSREvs2R9hJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smp49tHGR93C"
      },
      "source": [
        "# conda install -c conda-forge imbalanced-learn"
      ],
      "id": "smp49tHGR93C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ed048f9"
      },
      "source": [
        "# conda install -c conda-forge/label/cf201901 imbalanced-learn ### ensuring different version works"
      ],
      "id": "7ed048f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93b6e838"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "id": "93b6e838",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onP8gadSSnul"
      },
      "source": [
        ""
      ],
      "id": "onP8gadSSnul",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L9ABxCESoNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "0b3d2180-f659-4e68-a3c3-8eb16282581b"
      },
      "source": [
        "K-Clustering"
      ],
      "id": "5L9ABxCESoNq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1c84161066f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mClustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT6hhTKKSojj"
      },
      "source": [
        "X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
        "plt.scatter(X[:,0], X[:,1])"
      ],
      "id": "RT6hhTKKSojj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f19e669"
      },
      "source": [
        ""
      ],
      "id": "7f19e669",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3be1c861"
      },
      "source": [
        "#---------------------------------------------Importing Required Libraries-----------------------------------\n",
        "\n",
        "# library to help reading and data manuplation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# libraries to help with data visualisation\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Library to suppress warnings or deprecation notes \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython.display import display #------------------------for displaying multiple data frames in one output"
      ],
      "id": "3be1c861",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "739d80ba"
      },
      "source": [
        "# Remove the limit from the number of displayed columns and rows.\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# pd.set_option('display.max_rows' None)\n",
        "pd.set_option(\"display.max_rows\", 200)"
      ],
      "id": "739d80ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdd42a7d"
      },
      "source": [
        "# !pip install xgboost\n",
        "import xgboost"
      ],
      "id": "cdd42a7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74aadec3"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_excel('CreditCardCustomerData.xlsx', sheet_name='CreditCardCustomerData')\n",
        "\n",
        "df.head()"
      ],
      "id": "74aadec3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a3156af"
      },
      "source": [
        "df.info()\n",
        "pd.DataFrame(data={'% of Missing Values':round(df.isna().sum()/df.isna().count()*100,2)})\n",
        "df.isnull().sum()  #### Data Cleaning\n",
        "pd.DataFrame(data={'% of Missing Values':round(df.isna().sum()/df.isna().count()*100,2)})\n",
        "df.describe()\n"
      ],
      "id": "5a3156af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqOX9g8QN35D"
      },
      "source": [
        "Exploratory Data analysis. Possible points of vital analysis. Possible vital assumptions on individual variables and the relationship between variables. Credit Limit could indicate their spending power. It's also possible working female have more spending power though not state there. Total Credit Card may indicate banking customer number of card he has"
      ],
      "id": "QqOX9g8QN35D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7XXG0-hN51j"
      },
      "source": [
        "print(df['CustomerKey'].value_counts())\n",
        "print(\"-\"*50)\n",
        "print(df['Avg_Credit_Limit'].value_counts())\n",
        "print(\"-\"*50)\n",
        "print(df['Total_Credit_Cards'].value_counts())\n",
        "print(\"-\"*50)\n",
        "print(df['Total_visits_bank'].value_counts())\n",
        "print(\"-\"*50)\n",
        "print(df['Total_visits_online'].value_counts())\n",
        "print(\"-\"*50)\n",
        "print(df['Total_calls_made'].value_counts())\n",
        "print(\"-\"*50)\n"
      ],
      "id": "L7XXG0-hN51j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8w4qrUcex79"
      },
      "source": [
        "Boxplot"
      ],
      "id": "X8w4qrUcex79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hEqYf4FgCh-"
      },
      "source": [
        "sns.boxplot(df['Avg_Credit_Limit']);\n",
        "plt.title(\"Detecting outliers using Boxplot\");\n",
        "plt.xlabel('Credit_Limit');"
      ],
      "id": "2hEqYf4FgCh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT41_S2JgC8Q"
      },
      "source": [
        "Univariate analysis - Use appropriate visualizations to identify the patterns and insights - Come up with a customer profile (characteristics of a customer) of number of credit cards , number of visits - Any other exploratory deep dive"
      ],
      "id": "lT41_S2JgC8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL35X9CBgDZv"
      },
      "source": [
        "plt.figure(figsize=(20,20));\n",
        "\n",
        "plt.subplot(3,2,1)\n",
        "\n",
        "df['Customer_Key'].value_counts().plot(kind='bar', title='CreditCardCustomerData')\n",
        "\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.subplot(3,2,2)\n",
        "\n",
        "df['Avg_Credit_Limit'].value_counts().plot(kind='bar', title='CreditCardCustomerData')\n",
        "\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.subplot(3,2,3)\n",
        "\n",
        "df['MonthlyIncome'].value_counts().plot(kind='bar', title='CreditCardCustomerData')\n",
        "\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.subplot(3,2,4)\n",
        "\n",
        "df['Total_Credit_Cards'].value_counts().plot(kind='bar', title='CreditCardCustomerData')\n",
        "\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.subplot(3,2,5)\n",
        "\n",
        "df['Total_visits_online'].value_counts().plot(kind='bar', title='CreditCardCustomerData')\n",
        "\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.show()"
      ],
      "id": "eL35X9CBgDZv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F4D4mTrgDsu"
      },
      "source": [
        "Moving on with Univariate Analysis, we will be making a boxplot of the numerical columns ( ) in the dataset. A boxplot helps us in visualizing the data in terms of quartiles. as well as identifying outliers in the dataset. We will use the boxplot() function for this purpose as shown above"
      ],
      "id": "6F4D4mTrgDsu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ly-NAdVgEAG"
      },
      "source": [
        "sns.distplot(df['Total_calls_made'], kde=False)"
      ],
      "id": "8ly-NAdVgEAG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9F-MJWdgETH"
      },
      "source": [
        "plt.figure(figsize=(10,10));\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=True, square=True)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()   # show the plot\n"
      ],
      "id": "J9F-MJWdgETH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7bkCq-Ceyvf"
      },
      "source": [
        " Finding out about correlation between the various data with the help of a heatmap as shown above . Total_Credit_Cards has a strong positive correlation with Number of children visiting as well as number of persons visiting (ie. assuming if couple have more children, they have less cash to go around spend; likewise for adults total number of person visiting will affect budgeting and ultimately the number cards they want to have ) . The Number of persons visiting and Number of followups have correlation (ie. assuming proactive followups have persuade more people to visit through a discount . Age may show some correlation with average credit limit. (ie assuming someone in their 30s or 40s working adults have more disposable income for more credit cards against those above 60 years old) . Total credit cards have some correlation in their decision making"
      ],
      "id": "w7bkCq-Ceyvf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NticrqaPN44q"
      },
      "source": [
        ""
      ],
      "id": "NticrqaPN44q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0g9G3Pj27be"
      },
      "source": [
        "cols = df[['CustomerKey','Avg_Credit_Limit','Total_Credit_Cards','Total_visits_bank','Total_visits_online','']].columns.tolist()\n",
        "plt.figure(figsize=(18,7))\n",
        "\n",
        "for i, variable in enumerate(cols):\n",
        "                     plt.subplot(1,5,i+1)\n",
        "                     sns.boxplot(x=df[''],y=df[variable],palette=\"PuBu\")\n",
        "                     plt.tight_layout()\n",
        "                     plt.title(variable)\n",
        "plt.show()"
      ],
      "id": "I0g9G3Pj27be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqUNta5zRWN3"
      },
      "source": [
        "Bivarate Analysis"
      ],
      "id": "KqUNta5zRWN3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92uY9WZihghQ"
      },
      "source": [
        ""
      ],
      "id": "92uY9WZihghQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADIOA9_JhhMr"
      },
      "source": [
        "On Bivariate Analysis. We will look at a relational plot. This will helps us to understand the relationship between 2 variables on different subsets of the dataset. In this process we are trying to understand the relationship between the average credit limit and total credit card owned by workers or self-employed of different genders. (ie. On assumption, Different Gender may choose different type of credit card according to spending power, preference, value for money deals – on the basis of total visits online, total calls made)"
      ],
      "id": "ADIOA9_JhhMr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_VCQhXeRW3G"
      },
      "source": [
        "sns.relplot(x='Avg_Credit_Limit', y='Total_Credit_Cards', size='Total_visits_online', hue=' ', data=df)"
      ],
      "id": "h_VCQhXeRW3G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isdrCe3Lld6F"
      },
      "source": [
        "Missing imputations"
      ],
      "id": "isdrCe3Lld6F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N76c4HDleQK"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "si1=SimpleImputer(strategy='median')\n",
        "\n",
        "median_imputed_col=['Avg_Credit_Limit','Total_Credit_Cards','Total_visits_online','Total_visits_bank','Total_calls_made']\n",
        "\n",
        "#Fit and transform the train data\n",
        "df[median_imputed_col]=si1.fit_transform(df[median_imputed_col])"
      ],
      "id": "-N76c4HDleQK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eufVdu6zleiy"
      },
      "source": [
        "si2=SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "mode_imputed_col=['Avg_Credit_Limit','Total_Credit_Cards','Total_visits_online','Total_visits_bank','Total_calls_made']\n",
        "\n",
        "#Fit and transform the train data\n",
        "df[mode_imputed_col]=si2.fit_transform(df[mode_imputed_col])"
      ],
      "id": "eufVdu6zleiy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk6qSnJdNEb8"
      },
      "source": [
        ""
      ],
      "id": "Pk6qSnJdNEb8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A04GUMvYNEI-"
      },
      "source": [
        ""
      ],
      "id": "A04GUMvYNEI-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB5i2UmQNDY1"
      },
      "source": [
        "Moving on with Univariate Analysis, we will be making a boxplot of the numerical columns (math score, reading score, and writing score) in the dataset. A boxplot helps us in visualizing the data in terms of quartiles. as well as identifying outliers in the dataset. We will use the boxplot() function for this purpose as shown above"
      ],
      "id": "MB5i2UmQNDY1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1K55K2ele3O"
      },
      "source": [
        "sns.distplot(df['Avg_Credit_Limit'], kde=False)"
      ],
      "id": "q1K55K2ele3O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F73V58XxhiU8"
      },
      "source": [
        "plt.figure(figsize=(10,10));\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=True, square=True)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()   # show the plot"
      ],
      "id": "F73V58XxhiU8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk5ksZK1_7s-"
      },
      "source": [
        "cols = df[['Total_Credit_Cards','Avg_Credit_Limit','Total_visits_bank','Total_visits_online','Total_calls_made']].columns.tolist()\n",
        "plt.figure(figsize=(18,7))\n",
        "\n",
        "for i, variable in enumerate(cols):\n",
        "                     plt.subplot(1,5,i+1)\n",
        "                     sns.boxplot(x=df['Total_Credit_Cards'],y=df[variable],palette=\"PuBu\")\n",
        "                     plt.tight_layout()\n",
        "                     plt.title(variable)"
      ],
      "id": "Vk5ksZK1_7s-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgp5X4Xw_8C4"
      },
      "source": [
        "si2=SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "mode_imputed_col=['Avg_Credit_Limit','Total_Credit_Cards','Total_visits_bank','Total_visits_online','Total_calls_made']\n",
        "\n",
        "#Fit and transform the train data\n",
        "df[mode_imputed_col]=si2.fit_transform(df[mode_imputed_col])"
      ],
      "id": "Lgp5X4Xw_8C4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4L9QTRS_8UQ"
      },
      "source": [
        ""
      ],
      "id": "U4L9QTRS_8UQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LypeWKaG_8mH"
      },
      "source": [
        "Feature selection"
      ],
      "id": "LypeWKaG_8mH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuJAFK8M_89Q"
      },
      "source": [
        "## Encoding Existing and Attrited customers to 0 and 1 respectively, for analysis.\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "\n",
        "df[\"Attrition_Flag\"].replace(\"Existing Customer\", 0, inplace=True)\n",
        "df[\"Attrition_Flag\"].replace(\"Attrited Customer\", 1, inplace=True)\n",
        "\n",
        "X = df.drop([\"Attrition_Flag\"], axis=1)\n",
        "y = df[\"Attrition_Flag\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "id": "CuJAFK8M_89Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpWP6wm3_9RQ"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "reqd_col_for_impute = [\"Education_Level\", \"Marital_Status\", \"Income_Category\"]\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "# Fit and transform the train data\n",
        "X_train[reqd_col_for_impute] = imputer.fit_transform(X_train[reqd_col_for_impute])\n",
        "\n",
        "# Transform the test data\n",
        "X_test[reqd_col_for_impute] = imputer.transform(X_test[reqd_col_for_impute])"
      ],
      "id": "PpWP6wm3_9RQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrnhnLIu_9kQ"
      },
      "source": [
        "X_train.isnull().sum()\n"
      ],
      "id": "yrnhnLIu_9kQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYkcJ3TX_94c"
      },
      "source": [
        "X_test.isnull().sum()"
      ],
      "id": "rYkcJ3TX_94c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HklXa49W_-Kl"
      },
      "source": [
        "def model_performance(model, predictors, target):\n",
        "   \n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred)  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Recall\": recall,\n",
        "            \"Precision\": precision,\n",
        "            \"F1\": f1,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ],
      "id": "HklXa49W_-Kl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDN-dfex_-eO"
      },
      "source": [
        "def make_confusion_matrix(model,y_actual,labels=[1, 0]):\n",
        "    '''\n",
        "    model : classifier to predict values of X\n",
        "    y_actual : ground truth  \n",
        "    \n",
        "    '''\n",
        "    y_predict = model.predict(X_test)\n",
        "    cm=metrics.confusion_matrix( y_actual, y_predict, labels=[0, 1])\n",
        "    \n",
        "    df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual - No\",\"Actual - Yes\"]],\n",
        "                  columns = [i for i in ['Predicted - No','Predicted - Yes']])\n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cm.flatten()]\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                         cm.flatten()/np.sum(cm)]\n",
        "    \n",
        "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
        "              zip(group_counts,group_percentages)]\n",
        "    \n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    \n",
        "    plt.figure(figsize = (10,7))\n",
        "    sns.heatmap(df_cm, annot=labels,fmt='')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "id": "QDN-dfex_-eO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKnuXoO1sfHn"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight('balanced', np.unique(y_train), \n",
        "                y_train))) \n",
        "\n",
        "print(class_weights)"
      ],
      "id": "aKnuXoO1sfHn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ0NS5RwsfeY"
      },
      "source": [
        "# Library to suppress warnings or deprecation notes \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# Libraries to split data, impute missing values \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Libraries to import decision tree classifier and different ensemble classifiers\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Libtune to tune model, get different metric scores\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "id": "KZ0NS5RwsfeY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6MqA545sfvw"
      },
      "source": [
        ""
      ],
      "id": "r6MqA545sfvw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HZxBK8__-wv"
      },
      "source": [
        "K-Clustering "
      ],
      "id": "9HZxBK8__-wv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXNTv5wcoS8o"
      },
      "source": [
        "X, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
        "plt.scatter(X[:,0], X[:,1])\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 11), Total_Credit_cards)\n",
        "plt.title('Total Number of Transactions')\n",
        "plt.xlabel('Total_visits_Online')\n",
        "plt.ylabel('Total_Credit_cards')\n",
        "plt.show()\n"
      ],
      "id": "yXNTv5wcoS8o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYYGtNcToTOq"
      },
      "source": [
        "kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "pred_y = kmeans.fit_predict(X)\n",
        "plt.scatter(X[:,0], X[:,1])\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
        "plt.show()"
      ],
      "id": "NYYGtNcToTOq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-3NHzSvoTfT"
      },
      "source": [
        ""
      ],
      "id": "3-3NHzSvoTfT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqkfqosSoTyr"
      },
      "source": [
        ""
      ],
      "id": "yqkfqosSoTyr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zKuQWt5oUE2"
      },
      "source": [
        ""
      ],
      "id": "7zKuQWt5oUE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4KmHQE2oUYa"
      },
      "source": [
        ""
      ],
      "id": "T4KmHQE2oUYa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oszXayPoVeq"
      },
      "source": [
        "Hierarchical Clustering"
      ],
      "id": "8oszXayPoVeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XheTEyMvoWHr"
      },
      "source": [
        ""
      ],
      "id": "XheTEyMvoWHr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAq7WB6KoWiC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.cluster.hierarchy as hc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "#\n",
        "# Load the CSV file\n",
        "#\n",
        "df = pd.read_csv(\"CreditCardCustomerData.csv\")\n",
        "#\n",
        "# Drop the customer id column\n",
        "#\n",
        "df = df.drop('Customer Key', axis = 1)\n",
        "#\n",
        "# Fill the missing values with ffill method\n",
        "#\n",
        "df.fillna(method ='ffill', inplace = True)\n",
        "#\n",
        "# Scale the data and normalize\n",
        "#\n",
        "sc = StandardScaler()\n",
        "df_scaled = sc.fit_transform(df)\n",
        "df_normalized = normalize(df_scaled)\n",
        "#\n",
        "# Reduce the dimensionality of data to 3 features\n",
        "#\n",
        "pca = PCA(n_components=3)\n",
        "df_pca = pca.fit_transform(df_normalized)\n",
        "df_pca = pd.DataFrame(df_pca)\n",
        "df_pca.columns = ['P1', 'P2', 'P3']\n",
        "#\n",
        "# Create the Dendogram plot\n",
        "#\n",
        "plt.figure(figsize =(8, 8))\n",
        "plt.title('Visualising the data')\n",
        "dendrogram = hc.dendrogram((hc.linkage(df_pca, method ='ward')))"
      ],
      "id": "tAq7WB6KoWiC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMIx2u48oW4q"
      },
      "source": [
        ""
      ],
      "id": "CMIx2u48oW4q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ZMXISZoX1s"
      },
      "source": [
        ""
      ],
      "id": "J0ZMXISZoX1s",
      "execution_count": null,
      "outputs": []
    }
  ]
}